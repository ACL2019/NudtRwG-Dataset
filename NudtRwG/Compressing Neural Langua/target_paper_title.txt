Compressing Neural Language Models by Sparse Word Representations